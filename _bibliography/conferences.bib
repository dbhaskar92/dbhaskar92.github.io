@inproceedings{bhaskar_inferring_2024,
	title = {Inferring {Dynamic} {Regulatory} {Interaction} {Graphs} {From} {Time} {Series} {Data} {With} {Perturbations}},
	copyright = {All rights reserved},
	url = {https://proceedings.mlr.press/v231/bhaskar24a.html},
	abstract = {Complex systems are characterized by intricate interactions between entities that evolve dynamically over time. Accurate inference of these dynamic relationships is crucial for understanding and predicting system behavior. In this paper, we propose Regulatory Temporal Interaction Network Inference (RiTINI) for inferring time-varying interaction graphs in complex systems using a novel combination of space-and-time graph attentions and graph neural ordinary differential equations (ODEs). RiTINI leverages time-lapse signals on a graph prior, as well as perturbations of signals at various nodes in order to effectively capture the dynamics of the underlying system. This approach is distinct from traditional causal inference networks, which are limited to inferring acyclic and static graphs. In contrast, RiTINI can infer cyclic, directed, and time-varying graphs, providing a more comprehensive and accurate representation of complex systems. The graph attention mechanism in RiTINI allows the model to adaptively focus on the most relevant interactions in time and space, while the graph neural ODEs enable continuous-time modeling of the system’s dynamics. We evaluate RiTINI’s performance on simulations of dynamical systems, neuronal networks, and gene regulatory networks, demonstrating its state-of-the-art capability in inferring interaction graphs compared to previous methods.},
	language = {en},
	urldate = {2024-09-17},
	booktitle = {Proceedings of the {Second} {Learning} on {Graphs} {Conference}},
	publisher = {PMLR},
	author = {Bhaskar, Dhananjay and Magruder, Daniel Sumner and Morales, Matheo and Brouwer, Edward De and Venkat, Aarthi and Wenkel, Frederik and Noonan, James and Wolf, Guy and Ivanova, Natalia and Krishnaswamy, Smita},
	month = apr,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {22:1--22:21},
	abbr = {LoG}
}

@inproceedings{bhaskar_molecular_2022,
	title = {Molecular {Graph} {Generation} via {Geometric} {Scattering}},
	doi = {10.1109/MLSP55214.2022.9943379},
	abstract = {Although existing deep learning models perform remarkably well at predicting physicochemical properties and binding affinities, the generation of new molecules with optimized properties remains challenging. Inherently, most GNNs perform poorly in whole-graph representation due to the limitations of the message-passing paradigm. Furthermore, step-by-step graph generation frameworks that use reinforcement learning or other sequential processing can be slow and result in a high proportion of invalid molecules with substantial post-processing needed in order to generate valid molecules. To address these issues, we propose a representation-first approach to molecular graph generation. We guide the latent representation of an autoencoder by capturing graph structure information with the geometric scattering transform and apply penalties that organize the representation by molecular properties. We show that this highly structured latent space can be directly used for molecular graph generation by the use of a GAN. We demonstrate that our architecture learns meaningful representations of drug datasets and provides a platform for drug synthesis using publicly available ZINC and BindingDB datasets.},
	booktitle = {2022 {IEEE} 32nd {International} {Workshop} on {Machine} {Learning} for {Signal} {Processing} ({MLSP})},
	author = {Bhaskar, Dhananjay and Grady, Jackson and Castro, Egbert and Perlmutter, Michael and Krishnaswamy, Smita},
	month = aug,
	year = {2022},
	note = {ISSN: 2161-0371},
	keywords = {Deep learning, Transforms, Scattering, Signal processing, Conferences, Drug Discovery, Drugs, Geometric Scattering, Molecular Graph Generation, Reinforcement learning},
	pages = {1--6},
	abbr = {IEEE MLSP}
}

@inproceedings{macdonald_flow_2023,
	title = {A {Flow} {Artist} for {High}-{Dimensional} {Cellular} {Data}},
	url = {http://arxiv.org/abs/2308.00176},
	doi = {10.48550/arXiv.2308.00176},
	abstract = {We consider the problem of embedding point cloud data sampled from an underlying manifold with an associated flow or velocity. Such data arises in many contexts where static snapshots of dynamic entities are measured, including in high-throughput biology such as single-cell transcriptomics. Existing embedding techniques either do not utilize velocity information or embed the coordinates and velocities independently, i.e., they either impose velocities on top of an existing point embedding or embed points within a prescribed vector field. Here we present FlowArtist, a neural network that embeds points while jointly learning a vector field around the points. The combination allows FlowArtist to better separate and visualize velocity-informed structures. Our results, on toy datasets and single-cell RNA velocity data, illustrate the value of utilizing coordinate and velocity information in tandem for embedding and visualizing high-dimensional data.},
	urldate = {2023-08-11},
	booktitle = {2023 {IEEE} 33rd {International} {Workshop} on {Machine} {Learning} for {Signal} {Processing} ({MLSP})},
	author = {MacDonald, Kincaid and Bhaskar, Dhananjay and Thampakkul, Guy and Nguyen, Nhi and Zhang, Joia and Perlmutter, Michael and Adelstein, Ian and Krishnaswamy, Smita},
	year = {2023},
	abbr = {IEEE MLSP}
}

@article{bhaskar_diffusion_2022,
	title = {Diffusion {Curvature} for {Estimating} {Local} {Curvature} in {High} {Dimensional} {Data}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/88438dc62fc5c8777e2b5f1b4f6d37a2-Abstract-Conference.html},
	language = {en},
	urldate = {2023-07-24},
	journal = {Advances in Neural Information Processing Systems},
	author = {Bhaskar, Dhananjay and MacDonald, Kincaid and Fasina, Oluwadamilola and Thomas, Dawson and Rieck, Bastian and Adelstein, Ian and Krishnaswamy, Smita},
	month = dec,
	year = {2022},
	pages = {21738--21749},
	abbr = {NeurIPS}
}